{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from database_utils import Database\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadUserAgents(uafile):\n",
    "    uas = []\n",
    "    with open(uafile, 'rb') as uaf:\n",
    "        for ua in uaf.readlines():\n",
    "            if ua:\n",
    "                uas.append(ua.strip()[:-1])\n",
    "    random.shuffle(uas)\n",
    "    return uas\n",
    "\n",
    "uas = LoadUserAgents(\"user_agents.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 根据关键词查出所有视频的相关信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword=\"鸿蒙系统\"\n",
    "res=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按url获取当前页的视频列表\n",
    "def get_video_list(url):\n",
    "    res = requests.get(url)\n",
    "    res.encoding = 'utf-8'\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    all_videos = soup.find_all(name='ul',attrs={\"class\":\"video-contain clearfix\"})[0]\n",
    "    all_videos = all_videos.find_all(name='div', attrs={\"class\":\"info\"})\n",
    "    return all_videos\n",
    "# 从url中分离出up主id\n",
    "def get_up_id(url):\n",
    "    return url[url.index(\"com/\") + 4: url.index(\"?\")]\n",
    "# 获取视频中的信息\n",
    "def get_vider_data(source, res):\n",
    "    for i, every_video in enumerate(source):\n",
    "        data = {}\n",
    "        data['av_id'] = every_video.find_all(name='span', attrs={\"class\":\"type avid\"})[0].text[2:]\n",
    "        data['title'] = every_video.a['title']\n",
    "\n",
    "        tags = every_video.find_all(name='div', attrs={\"class\":\"tags\"})[0]\n",
    "        for j, s in enumerate(tags):\n",
    "            data[s['title']] = s.text.strip()\n",
    "            if j == 3:\n",
    "                data['up_id'] = get_up_id(s.a['href'])\n",
    "        res.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(1, 100):\n",
    "    url = r'https://search.bilibili.com/all?keyword=' + keyword +'&page=' + str(page)\n",
    "    video_list = get_video_list(url)\n",
    "    if len(video_list) == 0:\n",
    "        print(\"共%d页\"% (page - 1))\n",
    "        break\n",
    "    else:\n",
    "        get_vider_data(video_list, res)   \n",
    "\n",
    "video_info = pd.DataFrame(data=res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对视频信息进行补充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_other_info(row):\n",
    "    time.sleep(0.7)\n",
    "    oid = row['av_id']\n",
    "    print(oid)\n",
    "    head = {\n",
    "    'User-Agent': random.choice(uas),\n",
    "    'Connection': 'close'\n",
    "    } \n",
    "    requests.adapters.DEFAULT_RETRIES =5\n",
    "    curUrl = 'https://api.bilibili.com/x/web-interface/archive/stat?aid={}'.format(oid)\n",
    "    source = requests.get(curUrl, headers=head, timeout=3000).text       \n",
    "    source = json.loads(source)['data']\n",
    "    row['view']     = source['view']\n",
    "    row['reply']    = source['reply']\n",
    "    row['favorite'] = source['favorite']\n",
    "    row['coin']     = source['coin']\n",
    "    row['share']    = source['share']\n",
    "    row['like']     = source['like']\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info = video_info.apply(get_video_other_info, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info.sort_values('like', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info.to_csv(\"video_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 爬取所有视频的弹幕"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrages = []\n",
    "av_id_list = video_info[video_info['弹幕'] != '0']['av_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cid(avid):\n",
    "    source = requests.get(\"https://api.bilibili.com/x/web-interface/view?aid=\" + str(avid)).text\n",
    "    source = json.loads(source)\n",
    "    cid = source['data']['cid']\n",
    "    return cid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_name = ['video_time', 'barrage_type', 'font_size', 'font_color',\n",
    "             'time', 'barrage_pool_type', 'sender_id', 'barrage_id']\n",
    "def get_barrages(avid):\n",
    "    curr_list = []\n",
    "    cid = get_cid(avid)\n",
    "    source = requests.get(\"https://comment.bilibili.com/\"+ str(cid) +\".xml\")\n",
    "    source.encoding = 'utf-8'\n",
    "    source = BeautifulSoup(source.text, 'html.parser')\n",
    "    source = source.find_all(name='d')\n",
    "    for line in source:\n",
    "        data = {'av_id': avid, 'content': line.text}\n",
    "        for i, val in enumerate(line['p'].split(',')):\n",
    "            data[cols_name[i]] = val\n",
    "#     source = json.loads(source)\n",
    "        curr_list.append(data)\n",
    "    return curr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, avid in enumerate(av_id_list):\n",
    "    barrages += get_barrages(avid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrages_csv = pd.DataFrame(data=barrages)\n",
    "barrages_csv.to_csv(\"barrage_csv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrages_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 添加弹幕中的所有u_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uid(x):\n",
    "    res = database_util.get_uid(x)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "database_util = Database()\n",
    "barrages_csv['u_id'] = barrages_csv['sender_id'].apply(lambda x: get_uid(x))\n",
    "database_util.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrages_csv.to_csv(\"barrage_csv.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 获取弹幕中所有用户的信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrages_csv = pd.read_csv(\"barrage_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barrages_csv = barrages_csv[barrages_csv['u_id'].notnull()]\n",
    "barrages_csv['u_id'] = barrages_csv['u_id'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_info(uid):\n",
    "    \n",
    "    head = {\n",
    "    'User-Agent': random.choice(uas),\n",
    "    'Connection': 'close',\n",
    "    }\n",
    "    data = {'u_id': uid}\n",
    "    requests.adapters.DEFAULT_RETRIES =5\n",
    "    source = requests.get(\"https://api.bilibili.com/x/space/acc/info?mid=\"+ str(uid) +\"&jsonp=jsonp\",\\\n",
    "                          timeout=3000)\n",
    "    res = requests.get(\n",
    "                'https://api.bilibili.com/x/relation/stat?vmid=' + str(uid) + '&jsonp=jsonp').text\n",
    "    js_fans_data = json.loads(res)         \n",
    "    source = json.loads(source.text)['data']\n",
    "    data['name'] = source['name']\n",
    "    data['sex'] = source['sex']\n",
    "    data['sign'] = source['sign']\n",
    "    data['level'] = source['level']\n",
    "    data['birthday'] = source['birthday']\n",
    "    data['vip'] = 1 if source['vip']['status'] == 1 else 0 \n",
    "    data['following'] = js_fans_data['data']['following']\n",
    "    data['fans'] = js_fans_data['data']['follower']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_list = barrages_csv['u_id'].tolist()\n",
    "idx = -1\n",
    "while idx < len(user_list):\n",
    "    idx += 1\n",
    "    \n",
    "    if idx == len(user_list):\n",
    "        break\n",
    "        \n",
    "    try:\n",
    "        user_info_list.append(get_user_info(user_list[idx]))\n",
    "    except:\n",
    "        print(\"Connection refused by the server..and i is\" + str(idx))\n",
    "        time.sleep(5)\n",
    "        idx -= 1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_info = pd.DataFrame(data=user_info_list).drop_duplicates('u_id')\n",
    "user_info.to_csv('user_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 获取视频评论信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "def getPageCount(oid):\n",
    "    headers={\n",
    "        'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36',\n",
    "    }\n",
    "    baseurl = \"https://api.bilibili.com/x/v2/reply?type=1&oid=\"+str(oid)+\"&pn=\"+str(1)\n",
    "    r_text = requests.get(baseurl,headers).text\n",
    "    response = json.loads(r_text)\n",
    "    if 'data' in response:\n",
    "        count = response['data']['page']['count']\n",
    "        pages = math.ceil(count/20)\n",
    "    else:\n",
    "        print(oid)\n",
    "        pages = -1\n",
    "    return pages\n",
    "\n",
    "def fetchurl(oid):\n",
    "    time.sleep(0.7)\n",
    "    headers={\n",
    "        'accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.131 Safari/537.36',\n",
    "    }\n",
    "    r_text=[]\n",
    "    page_count = getPageCount(oid)\n",
    "    if page_count == -1:\n",
    "        return None\n",
    "    else:\n",
    "        for pn in range(1,page_count+1):\n",
    "            baseurl = \"https://api.bilibili.com/x/v2/reply?type=1&oid=\"+str(oid)+\"&pn=\"+str(pn)\n",
    "            r_text.append(requests.get(baseurl,headers).text)  \n",
    "    return r_text  \n",
    "\n",
    "def parse_text(html_text):  \n",
    "    if html_text is None:\n",
    "        return []\n",
    "    res = []\n",
    "    \n",
    "    for text in html_text:\n",
    "        response = json.loads(text)\n",
    "        for i in range(len(response['data']['replies'])):\n",
    "            replies = response['data']['replies'][i]\n",
    "            \n",
    "            data ={}\n",
    "            replies = response['data']['replies'][i]\n",
    "            data['u_id'] =  replies['mid']\n",
    "            data['rpid'] = replies['rpid']\n",
    "            data['oid'] = replies['oid']\n",
    "            data['ctime'] = replies['ctime']\n",
    "            data['review'] = replies['content']['message']\n",
    "            review_count = int(replies['rcount'])\n",
    "            data['parent_comment_id'] = 0\n",
    "            res.append(data)\n",
    "            source = response['data']['replies'][i]['replies']\n",
    "            if source is not None and len(source) != 0:\n",
    "                for j in range(len(response['data']['replies'][i]['replies'])):\n",
    "                    data ={}\n",
    "                    replies = response['data']['replies'][i]['replies'][j]\n",
    "                    data['rpid'] = replies['rpid']\n",
    "                    data['oid'] = replies['oid']\n",
    "                    data['ctime'] = replies['ctime']\n",
    "                    data['review'] = replies['content']['message']\n",
    "                    data['parent_comment_id'] = replies['parent_str']\n",
    "                    data['u_id'] = replies['mid']\n",
    "                    res.append(data)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_info = pd.read_csv('video_info.csv')\n",
    "oids = video_info['av_id'].tolist()\n",
    "oids = list(map(str, oids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection refused by the server..and i is8\n",
      "54970383\n"
     ]
    }
   ],
   "source": [
    "comments_data = []\n",
    "idx = -1\n",
    "while idx < len(oids):\n",
    "    idx += 1\n",
    "    \n",
    "    if idx == len(oids):\n",
    "        break  \n",
    "    try:\n",
    "        curr_list = parse_text(fetchurl(oids[idx]))\n",
    "        if len(curr_list) > 0:\n",
    "            comments_data += curr_list\n",
    "    except:\n",
    "        print(\"Connection refused by the server..and i is\" + str(idx))\n",
    "        time.sleep(5)\n",
    "        idx -= 1\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_info = pd.DataFrame(data=comments_data)\n",
    "comment_info.to_csv('comment_info.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
